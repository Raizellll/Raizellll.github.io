---
layout: page
permalink: /publications/index.html
title: Projects
---

# Projects

---

## Ongoing Projects

### ðŸ”¹ Deep Evaluation via Neural Activation Analysis  
*Supervisor: [Prof. Yixin Cao](https://www.caoyixin.site/), Fudan University*  

This project explores **how internal activations reflect model reasoning, confidence, and evaluation depth**. We aim to build a framework that interprets model behavior from its activation dynamics rather than output alone.  
My work focuses on identifying latent modularity across Transformer layers â€” clustering activations to reveal functional experts and connecting these to interpretability metrics. The goal is to establish a scalable evaluation paradigm that mirrors how humans assess reasoning quality: not just by the final answer, but by the structure and depth of thought inside the model.

---

### ðŸ”¹ Latent Expert Discovery and Post-hoc Modularization of Transformers  
*Summer Research with [Prof. Robert Dick](https://ece.engin.umich.edu/personnel/dick-robert), University of Michigan*  

This work investigates **how pretrained Transformers can be reorganized into interpretable, efficient expert structures without retraining**.  
I designed activation clustering and co-activation graph methods to uncover neuron-level communities that function as latent experts. The project bridges pruning and Mixture-of-Experts frameworks, showing how modular specialization emerges naturally in large models â€” a step toward efficiency that preserves interpretability.

---


## Earlier Explorations

- **Edge-Level Personal LLM for Multimodal Interaction:** This project develops a **personal multimodal LLM** capable of processing both speech and text inputs on resource-constrained devices. We explore *Oracle Mixture-of-Experts (MoE)* distillation and low-rank compression to enable lightweight yet adaptive inference, aiming for high personalization and efficiency. The ultimate goal is to make AI assistants not only accessible but meaningfully *personal*, running entirely at the edge.

- **Huawei Technologies (Janâ€“Feb 2025):** Designed a cognitive prompting pipeline for code generation with three-stage reasoning â€” problem decomposition, iterative refinement, and verification. Fine-tuned the *Qwen-2.5-72B* model on the *TACO* dataset (3,500 CodeForces problems) to study structured reasoning trajectories.  

- **CLIP-based Zero-Shot Classification:** Adapted CLIP for cross-domain text classification (*CLIPText*), validating zero-shot transfer and enhancing feature discrimination through adaptive training objectives.  

- **Urban Optimization Challenge (Francis Scott Key Bridge Collapse):** Engineered a data-driven redesign of Baltimoreâ€™s bus network following the bridge collapse, optimizing routes for accessibility, fairness, and efficiency.  

---

